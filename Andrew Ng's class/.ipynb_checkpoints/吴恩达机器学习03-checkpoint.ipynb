{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic 回归\n",
    "\n",
    "二分类问题 $\\begin{cases} if \\ h_\\theta(x) \\le 0.5 \\ predict \\ \"y=0\": \"Negative class\" \\\\ if \\ h_\\theta(x) > 0.5 \\ predict \\ \"y=1\" :\"Positive Class\" \\end{cases}$\n",
    "\n",
    "\n",
    "首先解释，在解决分类问题的时候，线性分类函数的效率就不是那么高了，因为在优化线性函数的时候，我们使用平均平方根误差，也就是说，如果在我们的数据点中如果存在离群点，那么线性函数很可能会偏向这个离群点，而导致其他一些点偏离预测，因此我们需要找到一个更好的函数取进行预测。\n",
    "\n",
    "\n",
    "有关logistic回归函数图像，查看PyML中的笔记。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 拟合logistic函数\n",
    "\n",
    " \n",
    "损失函数：$Cost(h_\\theta(x), y) = -y\\log(h_\\theta(x)) - (1-y)\\log(1-h_\\theta(x))$\n",
    "\n",
    "\n",
    "成本函数：$J(\\theta) = \\frac{1}{m}\\sum_{m}^{i=1}Cost(h_\\theta(x^{(i)}), y^{(i)}) = -\\frac{1}{m}[\\sum_{m}^{i=1}y^{(i)}\\log(h_\\theta(x^{(i)})) + (1-y^{(i)})\\log(1-h_\\theta(x^{(i)}))]$\n",
    "\n",
    "\n",
    "target： $\\min_\\theta J(\\theta)$ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
