{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 吴恩达人工智能课程第二周笔记六：Dropout正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了L2正则化。还有一个非常实用的正则化方法——**“Dropout（随机失活）”**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单来说，Dropout就是遍历神经网络，并设置每一层的神经网络节点失活的概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设每个节点以抛硬币的方式设置概率，那么每个节点保留和消除的概率都是0.5，设置完成概率后，我们会消除一些节点，然后删除从该节点进出的连线。得到一个节点更少，规模更小的网络，如下图：\n",
    "![nerul_network_6_1.png](img/nerul_network_6_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后用backprop方法进行训练，上面是对一个样本精简后的网络，对于其他的样本，我们依旧使用抛硬币的方式设置概率，保留一类节点集合，删除其他类型的节点集合，对于每个训练样本我们都采用精简后的网络来进行训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现Dropout\n",
    "以一个三层神经网络作为实例：\n",
    "\n",
    "首先要定义一个向量d3，d3表示一个第三层的dropout向量\n",
    "\n",
    "```python\n",
    "d3 = np.random.rand(a3.shape[0], a3.shape[1]) < keep-prob\n",
    "```\n",
    "\n",
    "在上面的例子中，keep-prob是0.5，在这个例子中我们使用keep-prob=0.8，它表示保留某个隐藏单元的概率。\n",
    "也就是说，在这个例子中，消除某个隐藏单元的概率是0.2。\n",
    "\n",
    "然后再让a3和这个向量相乘，即a3 = np.multiply(a3, d3)  也可以写作：a3 *= d3\n",
    "\n",
    "**在python中d3是一个bool型的列表，而不是0和1的列表**，但是乘法依然有效，python会把True和False翻译为1和0最后我们向外扩展a3，即\\\\(a3 /= (keepprob=0.8)\\\\)，之所以除以keep-prob是因为\\\\(Z^{[4]} = W^{[4]}A^{[3]}\\\\)执行Droput之后，\\\\(a[3]\\\\)会减少20%，也就是说\\\\(a[3]\\\\)中有20%的元素被归零，为了不影响\\\\(z[4]\\\\)的期望值，因此我们需要让\\\\(a[3]/0.8\\\\)来弥补我们之前设置的失活的神经元。\n",
    "\n",
    "事实证明，使用\\\\(a3/=keepprob\\\\)最终会使测试阶段变得更容易，因为它的数据扩展问题变少，目前Dropout常用的方法就是上面的方式，在Dropout早期的版本并没有上面的\\\\(a3/=keepprob\\\\)这个步骤，所以在测试阶段，平均值会变得越来越复杂。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 总结下来，Dropout步骤如下\n",
    "\n",
    "```python\n",
    "d3 = np.random.rand(a3.shape[0], a3.shape[1]) < keep-prob\n",
    "a3 = np.multiply(a3, d3)\n",
    "a3 /= keep-prob\n",
    "```\n",
    "如何在测试阶段训练算法，在测试阶段，我们已经给出了x，或者是想预测的变量，用的是标准计数法，**我们在测试阶段不使用Dropout函数**，也就不用再设置keep-prob变量去设置节点是否失活了。**因为在测试阶段，我们不希望最终的输出结果是随机的，如果在测试阶段使用dropout函数，那么预测就会受到干扰**。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
