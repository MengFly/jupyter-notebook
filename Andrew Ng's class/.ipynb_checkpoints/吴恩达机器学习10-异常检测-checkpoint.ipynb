{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 利用高斯分布（正态分布）进行异常 检测\n",
    "\n",
    "异常检测我们期望通过训练集得出一个概率模型，通过这个概率模型，我们可以进行预测, 新的样本点是不是属于异常样本点。\n",
    "\n",
    "其实结合高斯分布我们知道，高斯分布对于预测样本点有一定的帮助，对于偏离大量样本的点，高斯分布的输出其实就很小，我们可以利用它的这个特性来进行异常点检测，另外，如果我们想要使用高斯分布来进行样本点的异常检测，那么就应该有一个前提就是：至少我们的样本分布大致上应该符合高斯分布，当然，自然界中大部分的事物多多少少都符合高斯分布。\n",
    "\n",
    "另外一点就是，高斯分布的参数也比较容易进行计算。\n",
    "\n",
    "假如 $X \\sim N(\\mu, \\sigma^2)$ , 那么就有 $\\mu = EX, \\sigma^2 = D(X) = E(X-EX)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 高斯分布多特征概率预测\n",
    "\n",
    "对于多特征样本点来说，$x \\in \\mathbb{R}^n$ 有：\n",
    "\n",
    "$$p(x) = p(x_1;\\mu_1, \\sigma^2_1)p(x_2;\\mu_2, \\sigma^2_2)\\cdots p(x_n;\\mu_n, \\sigma^2_n) = \\prod_{i=1}^n{p(x_i;\\mu_i, \\sigma^2_i)}$$\n",
    "\n",
    "当然，这里假定所有的特征的分布大致符合高斯分布（正态分布）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 异常检测算法\n",
    "1. 选择合适的特征，尽量选择那些能表达样本是否异常的特征。\n",
    "2. 根据样本计算 $\\mu_1, \\dots, u_n, \\sigma^2_1, \\dots, \\sigma^2_n$\n",
    "3. 用新的样本点的到模型计算的 p,  根据 $p(x) < \\epsilon？$ 来判断是否是异常点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 异常检测需要监督数据吗？\n",
    "\n",
    "其实就是异常检测需要带标签的数据吗？在上面得到概率模型的算法中，其实并没有提到使用带标签的数据，那么需要带标签的数据吗？\n",
    "\n",
    "观察上面的算法，我们发现有一个问题没有解决，那就是参数 $\\epsilon$ 怎么确定，这个值非常关键，通过它我们才能把正常数据和异常数据分开来。\n",
    "\n",
    "也就是说，我们依旧是需要一些带标签的数据的，通过这些数据，我们要得到一个能够分类良好的 $\\epsilon$。\n",
    "\n",
    "这时候就需要把数据分为三部分：\n",
    "1. 训练集（无需带标签），这个训练集应该占整个数据集的大部分，并且不需要带标签，它的目的就是确定模型中各个特征高斯分布的参数值\n",
    "2. 交叉验证集（需要带标签），通过交叉验证机来确定参数 $\\epsilon$。\n",
    "3. 测试集（需要带标签），通过这个集合来验证模型的准确率。（当然，如果数据分布比较倾斜的话，一般来说异常值都会比较斜，这个时候全局的正确率就不能体现分类准确率指标了，这个时候可以使用之前提到的召回率以及查准率）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 异常检测 VS 监督学习\n",
    "\n",
    "异常检测其实可以使用监督学习来进行预测，反正都是对数据进行分类（是否是异常值）。而且使用监督学习可能还要比异常检测有更高的准确率，那么：什么时候应该使用异常检测，什么时候应该使用监督学习。\n",
    "\n",
    "1. 当某一项的例子数量非常少的时候，就不适合使用监督学习。因为当某一项例子数量非常多的时候，监督学习会倾向于拟合数量多的例子表现的特征，这就导致其结果达不到好的结果。\n",
    "2. 也就是说当不同分类结果的样本数量相当的时候适合使用监督学习。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如何选择特征？\n",
    "\n",
    "其实就是，查看特征的图像，查看是否符合高斯分布，一般来说就算不符合高斯分布，算法也能正常运行。但是是高斯分布则是一个理想的特征分布。对于一些不符合高斯分布的可以选择对特征进行运算后将它转换为类似于高斯分布再参与模型的运算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多元高斯分布\n",
    "\n",
    "Parameters: $\\mu, \\Sigma$\n",
    "\n",
    "$$p(x;\\mu, \\Sigma) = \\frac{1}{(2\\pi)^{\\frac{n}{2}|\\Sigma|^{\\frac{1}{2}}}} \\exp(-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu))$$\n",
    "\n",
    "Given training set X:\n",
    "\n",
    "$$\\mu = \\frac{1}{m}\\sum_{i=1}^{m}x^{(i)}$$\n",
    "$$\\Sigma = \\frac{1}{m}\\sum_{i=1}^{m}(x^{(i)} - \\mu)(x^{(i)}-\\mu)^T$$\n",
    "\n",
    "对比上面的高斯分布预测，只有在 $\\Sigma$ 除对角线外元素都为零，并且对角的元素依次是 $\\sigma_1^2, \\sigma_2^2, \\cdots, \\sigma_n^2$ 的时候，两个公式是相等的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多元 Or 原始模型\n",
    "\n",
    "1. 原始模型使用的更为频繁\n",
    "2. 但是多元模型更能捕捉复杂的特征之间的关系\n",
    "3. 原始模型的计算成本较低（多元要求逆）\n",
    "4. 多元模型的 m > n, 否则 $\\Sigma$ 不可逆，连伪逆都没有。原始函数没有这个限制。因此想要使用多元模型，至少 m >> n.\n",
    "5. 在多元模型中，如果发现 $\\Sigma$ 不可逆，可以查看是否有冗余的特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
